{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lazypredict_model_portfolio.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/x6PBq+WIa3YrUK6W85K8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/precise/blob/main/examples_colab_notebooks/lazypredict_model_portfolio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3HDL5HJ7Uyl"
      },
      "outputs": [],
      "source": [
        "!pip install lazypredict\n",
        "!pip install precise\n",
        "!pip install --upgrade pandas "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using LazyPredict and Precise to construct a portfolio of models \n",
        "\n",
        "\n",
        "*   [LazyPredict](https://github.com/shankarpandala/lazypredict) is a package that generates a slew of sklearn models \n",
        "*   [Precise](https://github.com/microprediction/precise) is a package that builds portfolios. \n",
        "\n",
        "Let's see if a convex combination (long portfolio) of models performs better than just picking the best out of sample model. I use the data example pulled straight from the LazyPredict README, in turn borrowed from sklearn. "
      ],
      "metadata": {
        "id": "Na-iVvJo7cuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from lazypredict.Supervised import LazyRegressor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKg4i7Ye73Yp",
        "outputId": "838b1691-e302-414f-baf1-c152234b838c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's what we do: \n",
        "\n",
        "1.  Train on X_train, y_train\n",
        "2.  Select best based on X_test, y_test out of sample performance\n",
        "3.  Retrain on X_train+X_test\n",
        "4.  Estimate portfolio using X_test,y_test covariance\n",
        "5.  Compare the val performance of:\n",
        "    - The best model from step 2, retrained in step 3.\n",
        "    - A weighted combination of models from step 4.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AEkC0YOe8xtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston = datasets.load_boston()\n",
        "X, y = shuffle(boston.data, boston.target)\n",
        "X = X.astype(np.float32)\n",
        "n_train = 100\n",
        "n_test = 50\n",
        "X_train, y_train = X[:n_train], y[:n_train]\n",
        "X_test, y_test = X[n_train:(n_train+n_test)], y[n_train:(n_train+n_test)]\n",
        "X_val, y_val = X[(n_train+n_test):], y[(n_train+n_test):]\n",
        "X_train_and_test = X[:(n_train+n_test)]\n",
        "y_train_and_test = y[:(n_train+n_test)]\n",
        "\n",
        "# Train on some, predict test\n",
        "reg1 = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None, predictions=True)\n",
        "models1, predictions1 = reg1.fit(np.copy(X_train), np.copy(X_test), np.copy(y_train), np.copy(y_test))\n",
        "print(models1[:5])\n",
        "\n",
        "# Train on some, predict validation\n",
        "reg2 = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None, predictions=True)\n",
        "X_train_and_test_copy = np.copy(X_train_and_test)\n",
        "X_val_copy = np.copy(X_val)\n",
        "models2, predictions2 = reg2.fit(X_train_and_test_copy, X_val_copy, np.copy(y_train_and_test), np.copy(y_val))\n",
        "yhat_val = predictions2.values\n",
        "print(models2[:5])\n",
        "\n",
        "# In-sample performance on train\n",
        "reg3 = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None, predictions=True)\n",
        "models3, predictions3 = reg3.fit(np.copy(X_train), np.copy(X_train), np.copy(y_train), np.copy(y_train))\n",
        "\n",
        "# In-sample performance on train + test\n",
        "reg4 = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None, predictions=True)\n",
        "models4, predictions4 = reg4.fit(np.copy(X_train_and_test), np.copy(X_train_and_test), np.copy(y_train_and_test), np.copy(y_train_and_test))\n",
        "\n",
        "best_model_1 = models1.index[0]  # <-- Best out of sample on test\n",
        "best_model_2 = models3.index[0]  # <-- Best in sample on train\n",
        "best_model_3 = models4.index[0]  # <-- Best in sample on train+test\n",
        "\n",
        "# Train cov on out of sample prediction errors\n",
        "print('Creating portfolio ...')\n",
        "from precise.skaters.managers.ppomanagers import ppo_sk_glcv_pcov_d0_n100_t0_vol_long_manager as mgr\n",
        "s = {}\n",
        "yhat_test = np.copy(predictions1.values)\n",
        "n_test = len(yhat_test)\n",
        "es = [-1]*(n_test-1)+[1]\n",
        "for y, y_target,e in zip(yhat_test, y_test,es):\n",
        "    y_error = np.copy(y-y_target)\n",
        "    w, s = mgr(s=s, y=y_error, e=e)\n",
        "\n",
        "w_dict = sorted([(wi,mi) for (wi,mi) in zip(w, models1.index) if wi>0], reverse=True)\n",
        "pprint(w_dict)\n",
        "\n",
        "# Refit models using all the train+test data, and combine\n",
        "sum_w = sum(w)\n",
        "yhat_weighted = np.dot( yhat_val, w )\n",
        "predictions2['>> weighted portfolio of models '] = yhat_weighted\n",
        "predictions2['>> best out of sample model  (' + best_model_1 + ')'] = predictions2[best_model_1]\n",
        "predictions2['>> best in sample i (' + best_model_2 + ')'] = predictions2[best_model_2]\n",
        "predictions2['>> best in sample ii (' + best_model_3 + ')'] = predictions2[best_model_3]\n",
        "\n",
        "val_errors = predictions2.copy()\n",
        "for col in predictions2.columns:\n",
        "    val_errors[col] = predictions2[col] - y_val\n",
        "\n",
        "sq_errors = val_errors**2\n",
        "print(sq_errors.mean().sort_values())\n",
        "print('done')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDwvX9YD8lr8",
        "outputId": "251632ee-68ba-4342-c490-039c05772a3b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 30/42 [00:01<00:00, 15.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPRegressor model failed to execute\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.34it/s]\n",
            "  2%|▏         | 1/42 [00:00<00:04,  9.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
            "Model                                                                       \n",
            "OrthogonalMatchingPursuitCV                0.77       0.83  3.53        0.04\n",
            "RandomForestRegressor                      0.76       0.83  3.56        0.23\n",
            "PoissonRegressor                           0.75       0.82  3.66        0.02\n",
            "BaggingRegressor                           0.73       0.80  3.84        0.04\n",
            "ExtraTreesRegressor                        0.72       0.80  3.86        0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 28/42 [00:01<00:01, 11.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPRegressor model failed to execute\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 16.87it/s]\n",
            "  5%|▍         | 2/42 [00:00<00:02, 15.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
            "Model                                                                     \n",
            "GradientBoostingRegressor                0.88       0.88  3.24        0.12\n",
            "RandomForestRegressor                    0.84       0.85  3.66        0.28\n",
            "ExtraTreesRegressor                      0.83       0.84  3.85        0.17\n",
            "BaggingRegressor                         0.83       0.83  3.86        0.04\n",
            "AdaBoostRegressor                        0.83       0.83  3.88        0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 30/42 [00:01<00:00, 15.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPRegressor model failed to execute\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 18.48it/s]\n",
            " 74%|███████▍  | 31/42 [00:01<00:00, 13.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPRegressor model failed to execute\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [00:02<00:00, 16.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating portfolio ...\n",
            "[(0.07594000000000001, 'DecisionTreeRegressor'),\n",
            " (0.059660000000000005, 'GeneralizedLinearRegressor'),\n",
            " (0.055560000000000005, 'KNeighborsRegressor'),\n",
            " (0.05206000000000001, 'NuSVR'),\n",
            " (0.04846000000000001, 'TransformedTargetRegressor'),\n",
            " (0.04558000000000001, 'PoissonRegressor'),\n",
            " (0.044770000000000004, 'LarsCV'),\n",
            " (0.04420000000000001, 'PassiveAggressiveRegressor'),\n",
            " (0.043030000000000006, 'LinearSVR'),\n",
            " (0.04299000000000001, 'XGBRegressor'),\n",
            " (0.04263000000000001, 'SVR'),\n",
            " (0.04241000000000001, 'LinearRegression'),\n",
            " (0.04241000000000001, 'GradientBoostingRegressor'),\n",
            " (0.04241000000000001, 'DummyRegressor'),\n",
            " (0.03783000000000001, 'BayesianRidge'),\n",
            " (0.029790000000000004, 'RandomForestRegressor'),\n",
            " (0.029210000000000003, 'Ridge'),\n",
            " (0.026990000000000004, 'TweedieRegressor'),\n",
            " (0.025740000000000002, 'KernelRidge'),\n",
            " (0.024570000000000005, 'OrthogonalMatchingPursuitCV'),\n",
            " (0.022060000000000003, 'Lars'),\n",
            " (0.019960000000000002, 'ElasticNet'),\n",
            " (0.019730000000000004, 'GaussianProcessRegressor'),\n",
            " (0.018320000000000003, 'LassoLarsCV'),\n",
            " (0.014460000000000002, 'RANSACRegressor'),\n",
            " (0.014240000000000001, 'BaggingRegressor'),\n",
            " (0.009740000000000002, 'GammaRegressor'),\n",
            " (0.009420000000000001, 'HuberRegressor'),\n",
            " (0.007860000000000002, 'LassoLarsIC'),\n",
            " (0.005240000000000001, 'SGDRegressor'),\n",
            " (0.0027300000000000002, 'LassoCV')]\n",
            "GradientBoostingRegressor                                     10.50\n",
            "RandomForestRegressor                                         13.43\n",
            "ExtraTreesRegressor                                           14.79\n",
            "BaggingRegressor                                              14.87\n",
            "AdaBoostRegressor                                             15.02\n",
            "XGBRegressor                                                  17.27\n",
            "HistGradientBoostingRegressor                                 18.90\n",
            "LGBMRegressor                                                 19.66\n",
            "PoissonRegressor                                              19.88\n",
            ">> weighted portfolio of models                               21.33\n",
            "KNeighborsRegressor                                           26.53\n",
            "Ridge                                                         26.81\n",
            "RidgeCV                                                       26.81\n",
            "TransformedTargetRegressor                                    26.83\n",
            "LinearRegression                                              26.83\n",
            "Lars                                                          26.83\n",
            "BayesianRidge                                                 26.86\n",
            "LassoCV                                                       26.87\n",
            "LassoLarsCV                                                   26.94\n",
            "LarsCV                                                        26.94\n",
            "ElasticNetCV                                                  26.97\n",
            "DecisionTreeRegressor                                         26.99\n",
            "HuberRegressor                                                27.34\n",
            "SGDRegressor                                                  27.51\n",
            "LinearSVR                                                     28.58\n",
            "GammaRegressor                                                30.47\n",
            ">> best out of sample model  (OrthogonalMatchingPursuitCV)    30.97\n",
            "OrthogonalMatchingPursuitCV                                   30.97\n",
            "ExtraTreeRegressor                                            32.30\n",
            "LassoLarsIC                                                   32.72\n",
            "TweedieRegressor                                              33.24\n",
            "GeneralizedLinearRegressor                                    33.24\n",
            "ElasticNet                                                    33.47\n",
            "Lasso                                                         33.85\n",
            "PassiveAggressiveRegressor                                    34.19\n",
            "RANSACRegressor                                               43.18\n",
            "NuSVR                                                         49.87\n",
            "SVR                                                           50.38\n",
            "OrthogonalMatchingPursuit                                     52.55\n",
            "DummyRegressor                                                89.74\n",
            "LassoLars                                                     89.74\n",
            ">> best in sample i (GaussianProcessRegressor)               152.84\n",
            "GaussianProcessRegressor                                     152.84\n",
            ">> best in sample ii (GaussianProcessRegressor)              152.84\n",
            "KernelRidge                                                  527.16\n",
            "dtype: float64\n",
            "done\n"
          ]
        }
      ]
    }
  ]
}
